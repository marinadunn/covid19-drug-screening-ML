{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd240322-0466-4e89-8e63-1c48203d6211",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70580e14-1ac1-40d3-87ee-0426419c142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "# sys\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "import numpy as np\n",
    "import os, sys\n",
    "from random import shuffle\n",
    "import h5py\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Machine Learning\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_score, accuracy_score, f1_score, recall_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Conv2D, Conv3D, MaxPool3D\n",
    "from tensorflow.keras.layers import Dropout, Dense\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "import scipy\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3abb9b21-77d7-461f-b883-085fb1646722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-learn Version:  1.1.1\n",
      "Scipy Version:  1.7.3\n",
      "Matplotlib Version:  3.5.2\n",
      "Tensorflow Version:  2.9.2\n",
      "Python Version:  3.10.0 (default, Mar  3 2022, 03:54:28) [Clang 12.0.0 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Scikit-learn Version: \", sklearn.__version__)\n",
    "print(\"Scipy Version: \", scipy.__version__)\n",
    "print(\"Matplotlib Version: \", matplotlib.__version__)\n",
    "print(\"Tensorflow Version: \", tf.__version__)\n",
    "print(\"Python Version: \", sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81e47a3-f6fd-450b-b9e0-591559218165",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86ee48d7-f3f2-4fa7-8cf1-d411211a830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3D_bounds(xyz):\n",
    "    \"\"\"\n",
    "    Finds min and max values of x, y, and z arrays.\n",
    "    \n",
    "    Example:\n",
    "        >>> import numpy as np\n",
    "        >>> xyz = np.array([[0, 1], [0, 0.3, 1], [0.1, 0.8, 1]])\n",
    "        >>> xmin, xmax, ymin, ymax, zmin, zmax = get_3D_bounds(xyz)\n",
    "        \n",
    "    Args:\n",
    "        xyz:\n",
    "            A numpy ndarray of with 3 columns and row number corresponding to number of atoms\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        xmin:\n",
    "            Minimum x coordinate in the array.\n",
    "        xmax:\n",
    "            Maximum x coordinate in the array.\n",
    "        ymin:\n",
    "            Minimum y coordinate in the array.\n",
    "        ymax:\n",
    "            Maximum y coordinate in the array.\n",
    "        zmin:\n",
    "            Minimum z coordinate in the array.\n",
    "        zmax:\n",
    "            Maximum z coordinate in the array.\n",
    "    \"\"\"\n",
    "    xmin = min(xyz[:, 0])\n",
    "    xmax = max(xyz[:, 0])\n",
    "    \n",
    "    ymin = min(xyz[:, 1])\n",
    "    ymax = max(xyz[:, 1])\n",
    "    \n",
    "    zmin = min(xyz[:, 2])\n",
    "    zmax = max(xyz[:, 2])\n",
    "    \n",
    "    return xmin, xmax, ymin, ymax, zmin, zmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d04ba53-8d4d-4f61-a7c0-9c5d76193873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def voxelizer(xyz, feats):\n",
    "    \"\"\"\n",
    "    Converts x, y, z, coordinate arrays into 3D voxelized data for each ligand.\n",
    "    \n",
    "    Args:\n",
    "        xyz:\n",
    "            A np.ndarray of columns containing the x, y, and z coordinates for every atom in ligand.\n",
    "        feats:\n",
    "            A np.ndarray of columns containing the feature values for every atom in ligand.\n",
    "\n",
    "    Returns:\n",
    "        A ndarray of shape (48, 48, 48, 19) representing the input data to be used \n",
    "        for model training.\n",
    "    \"\"\"\n",
    "    # Define variables\n",
    "    vol_dim = [48, 48, 48, 19] \n",
    "    atom_radius = 1\n",
    "    sigma = 0\n",
    "    \n",
    "    # Get 3D bounding box for data\n",
    "    xmin, xmax, ymin, ymax, zmin, zmax = get_3D_bounds(xyz)\n",
    "    \n",
    "    # Initialize volume data; create ndarray with dimensions 48x48x48x19\n",
    "    vol_data = np.zeros((vol_dim[0], vol_dim[1], vol_dim[2], vol_dim[3]), dtype=np.float32)\n",
    "    \n",
    "    # Assume same for all axes\n",
    "    vox_size = float(zmax - zmin) / vol_dim[0]\n",
    "    \n",
    "    # Assign each atom to voxels\n",
    "    num_atoms = xyz.shape[0]\n",
    "    for i in range(num_atoms):\n",
    "        x, y, z = xyz[i, 0], xyz[i, 1], xyz[i, 2]\n",
    "        \n",
    "        # Make sure coordinate is within volume space\n",
    "        if (x < xmin or x > xmax) or (y < ymin or y > ymax) or (z < zmin or z > zmax):\n",
    "            continue\n",
    "            \n",
    "        # atom ranges\n",
    "        cx = (x - xmin) / (xmax - xmin) * (vol_dim[2] - 1)\n",
    "        cy = (y - ymin) / (ymax - ymin) * (vol_dim[1] - 1)\n",
    "        cz = (z - zmin) / (zmax - zmin) * (vol_dim[0] - 1)\n",
    "\n",
    "        vx_from = max(0, int(cx - atom_radius))\n",
    "        vx_to = min(vol_dim[2] - 1, int(cx + atom_radius))\n",
    "        \n",
    "        vy_from = max(0, int(cy - atom_radius))\n",
    "        vy_to = min(vol_dim[1] - 1, int(cy + atom_radius))\n",
    "        \n",
    "        vz_from = max(0, int(cz - atom_radius))\n",
    "        vz_to = min(vol_dim[0] - 1, int(cz + atom_radius))\n",
    "\n",
    "        for vz in range(vz_from, vz_to + 1):\n",
    "            for vy in range(vy_from, vy_to + 1):\n",
    "                for vx in range(vx_from, vx_to + 1):\n",
    "                        vol_data[vz, vy, vx, :] += feats[i, :]\n",
    "    \n",
    "    # Gaussian filter: \n",
    "    if sigma > 0:\n",
    "        for i in range(vol_data.shape[-1]):\n",
    "            vol_data[:, :, :, i] = scipy.ndimage.gaussian_filter(vol_data[:, :, :, i], sigma = sigma,\n",
    "                                                                 truncate = 2 # Truncate filter at this many stdevs\n",
    "                                                                )\n",
    "    \n",
    "    return vol_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5565e7c3-5b27-4968-8465-59cd2452f994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3D_data(input_filepath):\n",
    "    \"\"\"\n",
    "    Reads HDF5 file and returns data and associated labels in the form of np.ndarray.\n",
    "    \n",
    "    Example:\n",
    "        >>> import numpy as np\n",
    "        >>> import h5py\n",
    "        >>> dataset = get_3D_data('data.hdf5')\n",
    "        \n",
    "    Args:\n",
    "        filepath:\n",
    "            A string listing the path where HDF5 file is located with data we \n",
    "            want to extract.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        data:\n",
    "            An np.ndarray of extracted data without labels.\n",
    "        labels:\n",
    "            An np.ndarray only containing truth labels.\n",
    "    \"\"\"\n",
    "    # Open hdf5 file and loads data\n",
    "    with h5py.File(input_filepath, 'r') as f:\n",
    "        \n",
    "        data = []\n",
    "        labels = []\n",
    "        \n",
    "        # Loop though all the compounds\n",
    "        for lig_id in f.keys():\n",
    "            \n",
    "            # Extract the ligand data, a 100 x 22 np.ndarray; rows correspond to atoms\n",
    "            ligand_data = f[lig_id]['ligand']\n",
    "            \n",
    "            # Remove zero padded rows (ligands with less than 100 atoms)\n",
    "            num_atoms = 0\n",
    "            for i in range(ligand_data.shape[0]):\n",
    "            # if sum of values in row is 0, remove\n",
    "                if np.sum(np.abs(ligand_data[i, :])) == 0:\n",
    "                    num_atoms = i\n",
    "                    break\n",
    "                    \n",
    "            # updated ligand data, now num_atoms x 22\n",
    "            input_data = ligand_data[0:num_atoms, :]\n",
    "            \n",
    "            # Ground truth label (0 = no bind, 1 = bind)\n",
    "            label = f[lig_id].attrs['label']\n",
    "            \n",
    "            # First 3 columns represent arrays of x, y, and z coordinates\n",
    "            xyz = input_data[:, 0:3]\n",
    "            \n",
    "            # Remaining 19 columns represent features: 10 one-hot encoded atomic \n",
    "            # number columns, Heavy Valence, Hetero Valence, Partial Charge, Mol Code,\n",
    "            # Hydrophobic, Aromatic, Acceptor, Donor, and Ring\n",
    "            feats = input_data[:, 3:]\n",
    "            \n",
    "            # Create 3D data, shape (48, 48, 48, 19)\n",
    "            vol_data = voxelizer(xyz, feats)\n",
    "            \n",
    "            # Add 3D data + label for each ligand to list\n",
    "            data.append(vol_data)\n",
    "            labels.append(label)\n",
    "            \n",
    "        # Convert lists to numpy arrays\n",
    "        data = np.asarray(data, dtype=np.float32)\n",
    "        labels = np.asarray(labels, dtype=np.float32)\n",
    "        \n",
    "        # Close original file\n",
    "        f.close()\n",
    "        \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e90b72c6-b3d0-437e-a9f3-ba818d91aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(X, y):\n",
    "    \"\"\"\n",
    "    \n",
    "    Converts data and labels in form of np.ndarray into tensors for training.\n",
    "    \n",
    "    Args:\n",
    "        X:\n",
    "            An np.ndarray of data for training.\n",
    "        y:\n",
    "            An np.ndarray of ground truth labels for training.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        dataset: \n",
    "            A tensor of data.\n",
    "        targets:\n",
    "            A tensor of ground truth labels.\n",
    "    \"\"\"\n",
    "    # Convert numpy arrays to tensors for training\n",
    "    dataset = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "    targets = tf.convert_to_tensor(y, dtype=tf.float32)\n",
    "    return dataset, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fd43fc-8f40-4f2b-95c3-9798dba71b9e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3D Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd36972d-2095-41f0-baa3-eff7e370407e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Define CNN Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "860a5b88-f2b0-4b01-acfa-a9c3265af70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_class_weights(train_labels):\n",
    "    \"\"\"\n",
    "    Generates class weights for a dataset given labels and prints them.\n",
    "    \n",
    "    Example:\n",
    "        >>> import numpy as np\n",
    "        >>> from sklearn.utils.class_weight import compute_class_weight\n",
    "        >>> X = np.array([1, 2])\n",
    "        >>> y = np.array([0, 1])\n",
    "        >>> class_weights = generate_class_weights(y)\n",
    "        {0: 0.5, 1: 0.5}\n",
    "        \n",
    "    Args:\n",
    "        train_labels:\n",
    "            A np.ndarray of ground truth labels for training.\n",
    "            \n",
    "    Returns:\n",
    "        A dictionary containing each label and its respective calculated weight.\n",
    "    \"\"\"\n",
    "    class_labels = np.unique(train_labels)\n",
    "    class_weights = compute_class_weight(class_weight = 'balanced',\n",
    "                                                      classes = class_labels,\n",
    "                                                      y = train_labels)\n",
    "    class_weights = dict(zip(class_labels, class_weights))\n",
    "    print('Class weights:', class_weights)\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9397eec2-76f7-4555-9344-d9dc79feec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model layers, build with the Functional API\n",
    "def create_model(inputs, outputs):\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61c61986-ef41-4612-86e4-d9f31f2eb3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "def compile_model(model, learning_rate):\n",
    "    \"\"\"\n",
    "    Compiles the model for training with specified optimizer, loss function, and metrics using the \n",
    "    tensorflow.keras.Model().compile() method, and prints a summary of the model \n",
    "    architecture.\n",
    "    \n",
    "    Args:\n",
    "        model:\n",
    "            A tensorflow.keras.models.Model object that includes Keras.Input and Keras.Output objects.\n",
    "            \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # use Adam optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    loss = 'binary_crossentropy'\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    \n",
    "    model.compile(optimizer = optimizer,\n",
    "                  loss = loss,\n",
    "                  metrics = metrics\n",
    "                 )\n",
    "\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f1f487c-21bb-41bd-bfdb-7e6873b5374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "def train_model(model, \n",
    "                train_data, \n",
    "                train_labels, \n",
    "                batch_size, \n",
    "                NUM_EPOCHS, \n",
    "                validation_data, \n",
    "                validation_labels, \n",
    "                class_weights, \n",
    "                callbacks\n",
    "               ):\n",
    "    \"\"\"\n",
    "    Trains the spacified model.\n",
    "    \n",
    "    Args:\n",
    "        model:\n",
    "            A compiled tensorflow.keras model object ready for training.\n",
    "        train_data:\n",
    "            A tensor of data for training.\n",
    "        train_labels:\n",
    "            A tensor of labels for training.\n",
    "        batch_size:\n",
    "            None or an integer determining the number of samples per batch of computation; defaults\n",
    "            to '32' if None.\n",
    "        NUM_EPOCHS:\n",
    "            An integer of how many epochs to train the model for.\n",
    "        validation_data:\n",
    "            A tensor of data for validation.\n",
    "        validation_labels:\n",
    "            A tensor of labels for training.\n",
    "        class_weights:\n",
    "            A dictionary containing each label and its respective calculated weight.\n",
    "        callbacks:\n",
    "            An optional list of keras.callbacks.Callback instances to use throughout model training.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        model:\n",
    "            A trained tensorflow.keras.models.Model object.\n",
    "        history:\n",
    "            A Tensorflow History object of a trained model returned by the \n",
    "            tensorflow.keras.Model().fit() method of models created from the \n",
    "            tensorflow.keras.callbacks.History() callback.\n",
    "    \"\"\"\n",
    "    history = model.fit(X_train, y_train,\n",
    "                    batch_size = 12,\n",
    "                    epochs = 100,\n",
    "                    validation_data = (X_val, y_val),                \n",
    "                    shuffle = True,\n",
    "                    class_weight = class_weights,\n",
    "                    verbose = 1,\n",
    "                    callbacks = es\n",
    "            )\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4698b681-8c8e-4b6a-8fe9-454719b43f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model on test data \n",
    "def evaluate_model(model, \n",
    "                   test_data, \n",
    "                   test_labels\n",
    "                  ):\n",
    "    \"\"\"\n",
    "    Evaluates the trained model on a set of test data and provides a score based on that \n",
    "    selected in 'metrics' variable in the function compile_model(), and prints scores.\n",
    "    \n",
    "    Args:\n",
    "        model:\n",
    "            A trained tensorflow.keras.models.Model object.\n",
    "        test_data:\n",
    "            A tensor of previously unseen data to use for evaluating the model.\n",
    "        test_labels:\n",
    "            A tensor of previously unseen labels associated with data from 'test_data'.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    model.evaluate(test_data, test_labels, verbose=True)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[0], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f46ef08d-ad0e-4f61-86ed-c30f5a64d4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_training(model, history):\n",
    "    \"\"\"\n",
    "    Create Matplotlib figures plotting the training history for a model configuration.\n",
    "    \n",
    "    Args:\n",
    "        model:\n",
    "            A trained tensorflow.keras.models.Model object.\n",
    "        history:\n",
    "            A Tensorflow History object of a trained model returned by the \n",
    "            tensorflow.keras.Model().fit() method of models created from the \n",
    "            tensorflow.keras.callbacks.History() callback.\n",
    "            \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Function to plot the Accuracy\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    # Function to plot the Loss\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = list(range(len(loss)))\n",
    "    \n",
    "    # plot accuracy\n",
    "    figsize=(6, 4)\n",
    "    figure = plt.figure(figsize=figsize)\n",
    "    plt.plot(epochs, acc, 'navy', label='Accuracy')\n",
    "    plt.plot(epochs, val_acc, 'deepskyblue', label= \"Validation Accuracy\")    \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(\"Accuracy Training History\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # plot loss\n",
    "    figsize=(6, 4)\n",
    "    figure = plt.figure(figsize=figsize)\n",
    "    plt.plot(epochs, loss, 'red', label='Loss')\n",
    "    plt.plot(epochs, val_loss, 'lightsalmon', label= \"Validation Loss\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(\"Loss Training History\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc071fdd-6061-4e31-84c2-7feb51574569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View confusion matrix and classification matrix\n",
    "def make_stats(model,\n",
    "               test_data, \n",
    "               test_labels,\n",
    "               class_names\n",
    "              ):\n",
    "    \"\"\"\n",
    "    For a trained model, creates and displays a confusion matrix and classification report.\n",
    "    \n",
    "    Args:\n",
    "        model:\n",
    "            A trained tensorflow.keras.models.Model object.\n",
    "        test_data:\n",
    "            A tensor of previously unseen data to be used to evaluate model.\n",
    "        test_labels:\n",
    "            A tensor of previously unseen labels associated with data from 'test_data'.\n",
    "            \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Confusion Matrix\n",
    "    y_pred = np.argmax(model.predict(test_data), axis=1)\n",
    "    y_test = np.argmax(test_labels, axis=1)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cd = ConfusionMatrixDisplay(cm, \n",
    "                                display_labels = class_names\n",
    "                               )\n",
    "    cd.plot()\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Classification report\n",
    "    classification_metrics = classification_report(y_test, \n",
    "                                                   y_pred, \n",
    "                                                   target_names = class_names\n",
    "                                                  )\n",
    "    print(classification_metrics + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5de5479-82a8-4e07-a95b-efa37498cbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "def save_model_data(model):\n",
    "    \"\"\"\n",
    "    Saves model training data and separate file for History object.\n",
    "    \n",
    "    Args:\n",
    "        model:\n",
    "            A trained tensorflow.keras.models.Model object.\n",
    "        history:\n",
    "            A Tensorflow History object of a trained model returned by the \n",
    "            tensorflow.keras.Model().fit() method of models created from the \n",
    "            tensorflow.keras.callbacks.History() callback.\n",
    "            \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    model.save(filepath = f'{model.name}', include_optimizer = True, \n",
    "               overwrite = True, save_format = 'h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4427d086-50d1-48d9-a0f3-4ffe40d24ea5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Main Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed80e9a7-7d6a-46c8-81b5-48b43d5cbcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load hdf5 files and generate 3D data for train, test, and validation datasets\n",
    "X_train, y_train = get_3D_data(\"data/postera_protease2_pos_neg_train.hdf5\")\n",
    "X_test, y_test = get_3D_data(\"data/postera_protease2_pos_neg_test.hdf5\")\n",
    "X_val, y_val = get_3D_data(\"data/postera_protease2_pos_neg_val.hdf5\")\n",
    "\n",
    "print(\"Number of samples in train are %d.\" % X_train.shape)\n",
    "print(\"Number of samples in test are %d.\" % X_test.shape)\n",
    "print(\"Number of samples in validation are %d.\" % X_val.shape)\n",
    "\n",
    "# Generate class weights for train dataset\n",
    "class_weights = generate_class_weights(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0b6c8a3-d584-4c36-a01b-296d64b288da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy arrays to tensors\n",
    "X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "\n",
    "X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "y_test = tf.convert_to_tensor(y_test, dtype=tf.float32)\n",
    "\n",
    "X_val = tf.convert_to_tensor(X_val, dtype=tf.float32)\n",
    "y_val = tf.convert_to_tensor(y_val, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7d8587b-df6d-41c5-908b-c8d5feab53bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 3D CNN variables\n",
    "class_names = ['No Bind', 'Bind'] # '0': No Bind, '1': Bind\n",
    "NUM_CLASSES = len(class_names)\n",
    "NUM_FEATURES = 19  # 19 feature dimensions\n",
    "NUM_TRAIN = 19533\n",
    "NUM_TEST = 1280\n",
    "NUM_VALIDATION = 1130\n",
    "NUM_TOTAL = NUM_TRAIN + NUM_TEST + NUM_VALIDATION\n",
    "input_shape = X_train.shape\n",
    "\n",
    "# Define callbacks\n",
    "es = [EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10),\n",
    "      ModelCheckpoint(filepath='best_weights.h5', monitor='val_accuracy',\n",
    "                      mode='max', verbose=0, save_best_only=True, save_freq='epoch')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c806f850-f61f-4cef-9bbf-0be3f840fee8",
   "metadata": {},
   "source": [
    "### Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a9496d3-6382-43dc-85f2-a1efa0d0172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 1 architecture\n",
    "inputs = Input(shape=input_shape)\n",
    "# Start with 32 5x5x5 filters\n",
    "x = Conv3D(filters=32, kernel_size=(5, 5, 5), activation='relu', strides=1, padding='same')(inputs)\n",
    "# Try without residual option 1\n",
    "x = Conv3D(filters=32, kernel_size=(5, 5, 5), activation='relu', strides=1, padding='same')(x)\n",
    "x = Conv3D(filters=32, kernel_size=(5, 5, 5), activation='relu', strides=1, padding='same')(x)\n",
    "# residual option 2\n",
    "x = Conv3D(filters=32, kernel_size=(5, 5, 5), activation='relu', strides=1, padding='same')(x)\n",
    "#-------------------\n",
    "x = Conv3D(filters=32, kernel_size=(5, 5, 5), activation='relu', strides=1, padding='same')(x)\n",
    "x = MaxPool3D(pool_size=1, strides=1, padding='same')\n",
    "# switch to 64 3x3x3 filters\n",
    "x = Conv3D(filters=64, kernel_size=(3, 3, 3), activation='relu', strides=1, padding='same')(x)\n",
    "x = MaxPool3D(pool_size=1, strides=1, padding='same')\n",
    "x = Conv3D(filters=64, kernel_size=(3, 3, 3), activation='relu', strides=1, padding='same')(x)\n",
    "x = MaxPool3D(pool_size=1, strides=1, padding='same')\n",
    "x = Conv3D(filters=64, kernel_size=(3, 3, 3), activation='relu', strides=1, padding='same')(x)\n",
    "x = MaxPool3D(pool_size=1, strides=1, padding='same')\n",
    "\n",
    "f = Flatten(data_format='channels_last')(x)\n",
    "\n",
    "# Use 128 Dense nodes\n",
    "d = Dense(128, activation='relu')(f)\n",
    "d = Dense(128, activation='relu')(d)\n",
    "# Here is where fusion would normally happen\n",
    "outputs = Dense(2, activation='softmax')(d)\n",
    "\n",
    "# Create & train\n",
    "print(\"Creating model\")\n",
    "model1 = create_model(inputs, outputs)\n",
    "compile_model(model1, learning_rate = 4.9e-5)\n",
    "print(\"Beginning Model 1 training\")\n",
    "model1, history1 = train_model(model1, X_train, y_train,\n",
    "                               batch_size = 12, \n",
    "                               NUM_EPOCHS = 150,\n",
    "                               shuffle = True,\n",
    "                               validation_data = (X_val, y_val),\n",
    "                               class_weights = class_weights,\n",
    "                               callbacks = es\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a8c8a76-e960-4a42-a42a-a6fd853e5166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "print(\"Beginning Model 1 testing\")\n",
    "evaluate_model(model1, X_test, y_test)\n",
    "save_model_data(model1)\n",
    "plot_training(model1, history1)\n",
    "make_stats(model1, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MuyGPs)",
   "language": "python",
   "name": "muygps"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
